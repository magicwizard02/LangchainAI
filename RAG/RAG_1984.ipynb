{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings, CacheBackedEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough, RunnableLambda \n",
    "from langchain.chains import LLMChain, StuffDocumentsChain\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(\"../.env\")  \n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Define Chat Model\n",
    "llm = ChatOpenAI(\n",
    "    model_name=\"gpt-3.5-turbo\", \n",
    "    temperature=0.1, \n",
    "    streaming=True, \n",
    "    callbacks=[StreamingStdOutCallbackHandler()],\n",
    "    openai_api_key=openai_api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/elinachoi/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/elinachoi/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    }
   ],
   "source": [
    "# Set up a local cache directory for storing embedding results\n",
    "cache_dir = LocalFileStore(\"./.cache/\")  # Ensure this directory exists or is writable\n",
    "\n",
    "# Create a text splitter using a token-based encoder with newline as a separator\n",
    "splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    separator=\"\\n\",       # Split text on newline characters\n",
    "    chunk_size=600,       # Maximum number of tokens per chunk\n",
    "    chunk_overlap=100,    # Overlap between chunks to preserve context between splits\n",
    ")\n",
    "\n",
    "# Load a text document and split the document\n",
    "loader = UnstructuredFileLoader(\"./ch3_1984.txt\")  \n",
    "\n",
    "docs = loader.load_and_split(text_splitter=splitter)\n",
    "\n",
    "# Initialize the OpenAI embedding model \n",
    "embeddings = OpenAIEmbeddings()\n",
    "# Wrap the embedding model with a caching mechanism to avoid redundant API calls\n",
    "cached_embeddings = CacheBackedEmbeddings.from_bytes_store(\n",
    "    embeddings,\n",
    "    cache_dir\n",
    ")\n",
    "\n",
    "# Create a FAISS vectorstore from the split documents and the cached embeddings\n",
    "vectorstore = FAISS.from_documents(docs, cached_embeddings)\n",
    "\n",
    "# Convert the vectorstore into a retriever for similarity-based document retrieval\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# Define a chat prompt template for answering questions based on retrieved context\n",
    "map_doc_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"\"\"\n",
    "            You are an expert at answering any questions about the document. \n",
    "            Use the following portion of a long document to answer the question. Answer based on the given context.\n",
    "            If there is no relevant text and you cannot answer, return : ''\n",
    "            -------\n",
    "            {context}\n",
    "        \"\"\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a memory buffer to retain conversation history\n",
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "# Create a basic LLMChain using the earlier defined prompt \n",
    "llm_chain = LLMChain(llm=llm, prompt=map_doc_prompt)\n",
    "# Wrap the LLM chain into a StuffDocumentsChain to allow processing multiple documents\n",
    "map_doc_chain = StuffDocumentsChain(\n",
    "    llm_chain=llm_chain,\n",
    "    memory=memory,\n",
    "    document_variable_name=\"context\"  \n",
    ")\n",
    "\n",
    "# Define a function to map over retrieved documents and answer the question \n",
    "def map_docs(inputs):\n",
    "    documents = inputs[\"documents\"]        # List of documents retrieved\n",
    "    question = inputs[\"question\"]          # Input question from the user\n",
    "    return \"\\n\\n\".join(\n",
    "        map_doc_chain.invoke(              # Call the document-processing chain for each document\n",
    "            {\"context\": doc.page_content, \"question\": question}\n",
    "        ).content\n",
    "        for doc in documents\n",
    "    )\n",
    "\n",
    "# Define the final prompt for combining partial document answers into a single response\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\n",
    "            Given the following extracted parts of a long document and a question, create a final answer. \n",
    "            If you don't know the answer, just say that you don't know. Don't try to make up an answer.\n",
    "            ------\n",
    "            {context}\n",
    "            \"\"\",\n",
    "        ),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define the overall processing chain:\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": retriever,              # Retrieve relevant documents from the vectorstore\n",
    "        \"question\": RunnablePassthrough(), # Pass question directly to the next stage\n",
    "        \"extra\": RunnablePassthrough(),    # Optional: extra input passed through, currently unused\n",
    "    }\n",
    "    | final_prompt                         # Format the context and question into a final prompt\n",
    "    | llm                                  # Call the LLM to generate the final answer\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, according to the document, Jones, Aaronson, and Rutherford were guilty of the crimes they were charged with."
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='Yes, according to the document, Jones, Aaronson, and Rutherford were guilty of the crimes they were charged with.')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"Is Aaronson guilty?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The message he wrote on the table was \"2+2=5.\""
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='The message he wrote on the table was \"2+2=5.\"')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"What message did he write in the table?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Julia is a character in the novel \"1984\" by George Orwell. She is a love interest of the protagonist, Winston Smith."
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='Julia is a character in the novel \"1984\" by George Orwell. She is a love interest of the protagonist, Winston Smith.')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"Who is Julia?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
